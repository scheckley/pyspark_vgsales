{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"Learning_Spark\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv('data/vgsales.csv',inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16719, 16)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count(), len(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+---------------+------------+---------+--------+--------+--------+-----------+------------+------------+------------+----------+----------+---------+------+\n",
      "|                Name|Platform|Year_of_Release|       Genre|Publisher|NA_Sales|EU_Sales|JP_Sales|Other_Sales|Global_Sales|Critic_Score|Critic_Count|User_Score|User_Count|Developer|Rating|\n",
      "+--------------------+--------+---------------+------------+---------+--------+--------+--------+-----------+------------+------------+------------+----------+----------+---------+------+\n",
      "|          Wii Sports|     Wii|           2006|      Sports| Nintendo|   41.36|   28.96|    3.77|       8.45|       82.53|          76|          51|         8|       322| Nintendo|     E|\n",
      "|   Super Mario Bros.|     NES|           1985|    Platform| Nintendo|   29.08|    3.58|    6.81|       0.77|       40.24|        null|        null|      null|      null|     null|  null|\n",
      "|      Mario Kart Wii|     Wii|           2008|      Racing| Nintendo|   15.68|   12.76|    3.79|       3.29|       35.52|          82|          73|       8.3|       709| Nintendo|     E|\n",
      "|   Wii Sports Resort|     Wii|           2009|      Sports| Nintendo|   15.61|   10.93|    3.28|       2.95|       32.77|          80|          73|         8|       192| Nintendo|     E|\n",
      "|Pokemon Red/Pokem...|      GB|           1996|Role-Playing| Nintendo|   11.27|    8.89|   10.22|        1.0|       31.37|        null|        null|      null|      null|     null|  null|\n",
      "+--------------------+--------+---------------+------------+---------+--------+--------+--------+-----------+------------+------------+------------+----------+----------+---------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Platform: string (nullable = true)\n",
      " |-- Year_of_Release: string (nullable = true)\n",
      " |-- Genre: string (nullable = true)\n",
      " |-- Publisher: string (nullable = true)\n",
      " |-- NA_Sales: double (nullable = true)\n",
      " |-- EU_Sales: double (nullable = true)\n",
      " |-- JP_Sales: double (nullable = true)\n",
      " |-- Other_Sales: double (nullable = true)\n",
      " |-- Global_Sales: double (nullable = true)\n",
      " |-- Critic_Score: integer (nullable = true)\n",
      " |-- Critic_Count: integer (nullable = true)\n",
      " |-- User_Score: string (nullable = true)\n",
      " |-- User_Count: integer (nullable = true)\n",
      " |-- Developer: string (nullable = true)\n",
      " |-- Rating: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+--------+----------+----------+\n",
      "|Name                       |Platform|User_Score|User_Count|\n",
      "+---------------------------+--------+----------+----------+\n",
      "|Wii Sports                 |Wii     |8         |322       |\n",
      "|Super Mario Bros.          |NES     |null      |null      |\n",
      "|Mario Kart Wii             |Wii     |8.3       |709       |\n",
      "|Wii Sports Resort          |Wii     |8         |192       |\n",
      "|Pokemon Red/Pokemon Blue   |GB      |null      |null      |\n",
      "|Tetris                     |GB      |null      |null      |\n",
      "|New Super Mario Bros.      |DS      |8.5       |431       |\n",
      "|Wii Play                   |Wii     |6.6       |129       |\n",
      "|New Super Mario Bros. Wii  |Wii     |8.4       |594       |\n",
      "|Duck Hunt                  |NES     |null      |null      |\n",
      "|Nintendogs                 |DS      |null      |null      |\n",
      "|Mario Kart DS              |DS      |8.6       |464       |\n",
      "|Pokemon Gold/Pokemon Silver|GB      |null      |null      |\n",
      "|Wii Fit                    |Wii     |7.7       |146       |\n",
      "|Kinect Adventures!         |X360    |6.3       |106       |\n",
      "+---------------------------+--------+----------+----------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select(\"Name\",\"Platform\",\"User_Score\",\"User_Count\") \\\n",
    ".show(15, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+\n",
      "|summary|        User_Score|        User_Count|   Year_of_Release|\n",
      "+-------+------------------+------------------+------------------+\n",
      "|  count|             10015|              7590|             16719|\n",
      "|   mean|7.1250461133070315|162.22990777338603|2006.4873556231003|\n",
      "| stddev|1.5000060936257986| 561.2823262473789|5.8789947683491475|\n",
      "|    min|                 0|                 4|              1980|\n",
      "|    max|               tbd|             10665|               N/A|\n",
      "+-------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.describe([\"User_Score\",\"User_Count\",\"Year_of_Release\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some strings in the user_score \"tbd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Platform|count|\n",
      "+--------+-----+\n",
      "|     PS2| 2161|\n",
      "|      DS| 2152|\n",
      "|     PS3| 1331|\n",
      "|     Wii| 1320|\n",
      "|    X360| 1262|\n",
      "|     PSP| 1209|\n",
      "|      PS| 1197|\n",
      "|      PC|  974|\n",
      "|      XB|  824|\n",
      "|     GBA|  822|\n",
      "+--------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.groupBy(\"Platform\") \\\n",
    ".count() \\\n",
    ".orderBy(\"count\", ascending=False) \\\n",
    ".show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new dataframe to remove Null values in User_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition1 = (data.User_Score.isNotNull()) | (data.User_Count.isNotNull())\n",
    "condition2 = data.User_Score != \"tbd\"\n",
    "\n",
    "data = data.filter(condition1).filter(condition2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition1 = (data.Critic_Score.isNotNull()) | (data.Critic_Count.isNotNull())\n",
    "condition2 = data.User_Score != \"tbd\"\n",
    "\n",
    "data = data.filter(condition1).filter(condition2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition1 = (data.Developer.isNotNull())\n",
    "data = data.filter(condition1)\n",
    "\n",
    "condition1 = (data.Rating.isNotNull())\n",
    "data = data.filter(condition1)\n",
    "\n",
    "condition1 = (data.Year_of_Release.isNotNull())\n",
    "data = data.filter(condition1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.filter(data.Rating.isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+---------------+--------+---------+--------+--------+--------+-----------+------------+------------+------------+----------+----------+---------+------+\n",
      "|                Name|Platform|Year_of_Release|   Genre|Publisher|NA_Sales|EU_Sales|JP_Sales|Other_Sales|Global_Sales|Critic_Score|Critic_Count|User_Score|User_Count|Developer|Rating|\n",
      "+--------------------+--------+---------------+--------+---------+--------+--------+--------+-----------+------------+------------+------------+----------+----------+---------+------+\n",
      "|          Wii Sports|     Wii|           2006|  Sports| Nintendo|   41.36|   28.96|    3.77|       8.45|       82.53|          76|          51|         8|       322| Nintendo|     E|\n",
      "|      Mario Kart Wii|     Wii|           2008|  Racing| Nintendo|   15.68|   12.76|    3.79|       3.29|       35.52|          82|          73|         8|       709| Nintendo|     E|\n",
      "|   Wii Sports Resort|     Wii|           2009|  Sports| Nintendo|   15.61|   10.93|    3.28|       2.95|       32.77|          80|          73|         8|       192| Nintendo|     E|\n",
      "|New Super Mario B...|      DS|           2006|Platform| Nintendo|   11.28|    9.14|     6.5|       2.88|        29.8|          89|          65|         8|       431| Nintendo|     E|\n",
      "|            Wii Play|     Wii|           2006|    Misc| Nintendo|   13.96|    9.18|    2.93|       2.84|       28.92|          58|          41|         6|       129| Nintendo|     E|\n",
      "+--------------------+--------+---------------+--------+---------+--------+--------+--------+-----------+------------+------------+------------+----------+----------+---------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+------------------+-----------------+\n",
      "|summary|        User_Score|       User_Count|      Critic_Count|     Critic_Score|\n",
      "+-------+------------------+-----------------+------------------+-----------------+\n",
      "|  count|              6826|             6826|              6826|             6826|\n",
      "|   mean| 6.736155874597129|174.7480222677996|28.931145619689424|70.26867858189276|\n",
      "| stddev|1.4611860669901755|587.3893323682087|19.222756806940907|13.87041674151392|\n",
      "|    min|                 0|                4|                 3|               13|\n",
      "|    max|                 9|            10665|               113|               98|\n",
      "+-------+------------------+-----------------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.describe([\"User_Score\",\"User_Count\",\"Critic_Count\",\"Critic_Score\"]).show() #seems clean now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an example of **linear regression**, let’s see if we can predict User_Score from Year_of_Release, Global_Sales, Critic_Score, and User_Count.\n",
    "\n",
    "First let’s recode all of our predictors to be Doubles (I found that this got rid of some really gnarly errors later on)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType, IntegerType\n",
    "\n",
    "data = data.withColumn(\"Year_of_Release\", data[\"Year_of_Release\"].cast(DoubleType()))\n",
    "\n",
    "data = data.withColumn(\"User_Score\", data[\"User_Score\"].cast(DoubleType()))\n",
    "\n",
    "data = data.withColumn(\"User_Count\", data[\"User_Count\"].cast(DoubleType()))\n",
    "\n",
    "data = data.withColumn(\"Critic_Score\", data[\"Critic_Score\"].cast(DoubleType()))\n",
    "\n",
    "data = data.withColumn(\"Critic_Score\", data[\"Critic_Score\"].cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Name', 'string'),\n",
       " ('Platform', 'string'),\n",
       " ('Year_of_Release', 'double'),\n",
       " ('Genre', 'string'),\n",
       " ('Publisher', 'string'),\n",
       " ('NA_Sales', 'double'),\n",
       " ('EU_Sales', 'double'),\n",
       " ('JP_Sales', 'double'),\n",
       " ('Other_Sales', 'double'),\n",
       " ('Global_Sales', 'double'),\n",
       " ('Critic_Score', 'double'),\n",
       " ('Critic_Count', 'int'),\n",
       " ('User_Score', 'double'),\n",
       " ('User_Count', 'double'),\n",
       " ('Developer', 'string'),\n",
       " ('Rating', 'string')]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.filter(data.Year_of_Release.isNull()).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VectorAssembler\n",
    "The next step is to get our data into a form that PySpark can create a model with. To do this we use something called a VectorAssembler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "inputcols = [\"Year_of_Release\", \"Global_Sales\", \"Critic_Score\", \"User_Count\"]\n",
    "\n",
    "assembler = VectorAssembler(inputCols = inputcols,\n",
    "                            outputCol = \"predictors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we’ve delineated what features we want our model to use as predictors so that VectorAssembler can take those columns and transform them into a single column (named “predictors”) that contains all the data we want to predict with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name',\n",
       " 'Platform',\n",
       " 'Year_of_Release',\n",
       " 'Genre',\n",
       " 'Publisher',\n",
       " 'NA_Sales',\n",
       " 'EU_Sales',\n",
       " 'JP_Sales',\n",
       " 'Other_Sales',\n",
       " 'Global_Sales',\n",
       " 'Critic_Score',\n",
       " 'Critic_Count',\n",
       " 'User_Score',\n",
       " 'User_Count',\n",
       " 'Developer',\n",
       " 'Rating',\n",
       " 'predictors']"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = assembler.transform(data)\n",
    "\n",
    "predictors.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What VectorAssembler.transform() does is create a new DataFrame with a new column at the end where each row contains a list of all the features we included in the inputCols parameter when we created the assembler.\n",
    "\n",
    "The final step to getting our data ready to be used in a model is to collect the new predictions column we just made and User_Score (our target variable) by themselves in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+----------+\n",
      "|predictors               |User_Score|\n",
      "+-------------------------+----------+\n",
      "|[2006.0,82.53,76.0,322.0]|8.0       |\n",
      "|[2008.0,35.52,82.0,709.0]|8.0       |\n",
      "|[2009.0,32.77,80.0,192.0]|8.0       |\n",
      "|[2006.0,29.8,89.0,431.0] |8.0       |\n",
      "|[2006.0,28.92,58.0,129.0]|6.0       |\n",
      "+-------------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_data = predictors.select(\"predictors\", \"User_Score\")\n",
    "\n",
    "model_data.show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = model_data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-0.02745162209083305,0.0,0.04131079521461806,0.0]\n",
      "Intercept: 58.9406467144236\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr = LinearRegression(featuresCol = 'predictors', labelCol='User_Score', maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "lr_model = lr.fit(train_data)\n",
    "print(\"Coefficients: \" + str(lr_model.coefficients))\n",
    "print(\"Intercept: \" + str(lr_model.intercept))\n",
    "\n",
    "pred = lr_model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "eval = RegressionEvaluator(\n",
    "    labelCol=\"User_Score\", \n",
    "    predictionCol=\"prediction\", \n",
    "    metricName=\"rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.1804929078473727\n",
      "MSE: 1.3935635054779456\n",
      "MAE: 0.896775202343803\n",
      "R squared: 0.31927745469019386\n"
     ]
    }
   ],
   "source": [
    "rmse = eval.evaluate(pred.predictions)\n",
    "mse = eval.evaluate(pred.predictions, {eval.metricName: \"mse\"})\n",
    "mae = eval.evaluate(pred.predictions, {eval.metricName: \"mae\"})\n",
    "r2 = eval.evaluate(pred.predictions, {eval.metricName: \"r2\"})\n",
    "\n",
    "print(\"RMSE: \" + str(rmse))\n",
    "print(\"MSE: \" + str(mse))\n",
    "print(\"MAE: \" + str(mae))\n",
    "print(\"R squared: \" + str(r2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|       User_Score|\n",
      "+-------+-----------------+\n",
      "|  count|             4783|\n",
      "|   mean|6.738657746184403|\n",
      "| stddev|1.473970600587042|\n",
      "|    min|              0.0|\n",
      "|    max|              9.0|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is accounting for about 40% of the variation in the data. Can we do better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+--------------------+\n",
      "|       prediction|User_Score|          predictors|\n",
      "+-----------------+----------+--------------------+\n",
      "|7.010712891583047|       2.0|[1988.0,0.03,64.0...|\n",
      "|7.052557135111144|       6.0|[1994.0,1.27,69.0...|\n",
      "| 7.57600502393413|       7.0|[1996.0,0.14,83.0...|\n",
      "|7.906491385651073|       8.0|[1996.0,4.63,91.0...|\n",
      "|7.823869795221839|       8.0|[1996.0,5.74,89.0...|\n",
      "+-----------------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "R Squared (R2) on test data = 0.319277\n"
     ]
    }
   ],
   "source": [
    "lr_predictions = lr_model.transform(test_data)\n",
    "lr_predictions.select(\"prediction\",\"User_Score\",\"predictors\").show(5)\n",
    "\n",
    "lr_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"User_Score\",metricName=\"r2\")\n",
    "print(\"R Squared (R2) on test data = %g\" % lr_evaluator.evaluate(lr_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient-boosted tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+--------------------+\n",
      "|       prediction|User_Score|          predictors|\n",
      "+-----------------+----------+--------------------+\n",
      "|5.658324803912353|       2.0|[1988.0,0.03,64.0...|\n",
      "|6.679882136924183|       6.0|[1994.0,1.27,69.0...|\n",
      "|6.953429385784522|       7.0|[1996.0,0.14,83.0...|\n",
      "|8.606887120844258|       8.0|[1996.0,4.63,91.0...|\n",
      "|8.606887120844258|       8.0|[1996.0,5.74,89.0...|\n",
      "+-----------------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import GBTRegressor\n",
    "\n",
    "gbt = GBTRegressor(featuresCol = 'predictors', labelCol = 'User_Score', maxIter=10)\n",
    "gbt_model = gbt.fit(train_data)\n",
    "gbt_predictions = gbt_model.transform(test_data)\n",
    "gbt_predictions.select('prediction', 'User_Score', 'predictors').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 1.12591\n",
      "R squared on test data = 0.380768\n"
     ]
    }
   ],
   "source": [
    "gbt_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"User_Score\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = gbt_evaluator.evaluate(gbt_predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "gbt_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"User_Score\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "rsquared = gbt_evaluator.evaluate(gbt_predictions)\n",
    "print(\"R squared on test data = %g\" % rsquared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+--------------------+\n",
      "|       prediction|User_Score|          predictors|\n",
      "+-----------------+----------+--------------------+\n",
      "|7.010712891583047|       2.0|[1988.0,0.03,64.0...|\n",
      "|7.052557135111144|       6.0|[1994.0,1.27,69.0...|\n",
      "| 7.57600502393413|       7.0|[1996.0,0.14,83.0...|\n",
      "|7.906491385651073|       8.0|[1996.0,4.63,91.0...|\n",
      "|7.823869795221839|       8.0|[1996.0,5.74,89.0...|\n",
      "+-----------------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "R Squared (R2) on test data = 0.380768\n"
     ]
    }
   ],
   "source": [
    "gbt_predictions = gbt_model.transform(test_data)\n",
    "lr_predictions.select(\"prediction\",\"User_Score\",\"predictors\").show(5)\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "gbt_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"User_Score\",metricName=\"r2\")\n",
    "print(\"R Squared (R2) on test data = %g\" % gbt_evaluator.evaluate(gbt_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
